# Kafka-Based Trading Mode Architecture

This document describes the new Kafka-based trading mode architecture that provides a unified interface for Backtest and Paper Trading modes using real-time data streams.

## Overview

The new architecture introduces a common `TradingMode` trait that all trading modes implement, with Kafka integration for consuming features and publishing signals. This allows for:

- **Consistent Interface**: All trading modes follow the same pattern of consuming features and producing signals
- **Real-time Processing**: Features are consumed from Kafka topics in real-time
- **Scalability**: Multiple trading strategy instances can consume from the same topics
- **Testability**: Easy integration testing with mock Kafka clusters

## Architecture Components

### 1. TradingMode Trait

```rust
#[async_trait]
pub trait TradingMode: Send + Sync {
    async fn start(&mut self) -> Result<()>;
    async fn stop(&mut self) -> Result<()>;
    async fn process_feature(&mut self, feature: Feature) -> Result<Option<Signal>>;
    fn get_mode_name(&self) -> &str;
}
```

### 2. Kafka Integration

- **KafkaHandler**: Manages Kafka consumer and producer connections
- **Feature**: Data structure for market features (price, volume, indicators)
- **Signal**: Trading signals generated by strategies (buy/sell/hold)

### 3. Trading Modes

#### BacktestTradingMode
- Consumes features from Kafka topics
- Processes historical data in batch during stop()
- Generates mock signals during feature processing
- Integrates with existing backtest infrastructure

#### PaperTradingMode
- Real-time feature processing
- Maintains virtual portfolio
- Executes trades immediately when signals are generated
- Provides performance metrics and portfolio tracking

## Data Flow

```
Feature Generator → Kafka (features topic) → Trading Mode → Kafka (signals topic)
                                                   ↓
                                            Portfolio/Results
```

1. **Feature Generation**: External services publish market features to Kafka
2. **Feature Consumption**: Trading modes consume features in real-time
3. **Signal Generation**: Strategy logic processes features and generates signals
4. **Signal Publishing**: Signals are published to Kafka for downstream consumers
5. **Trade Execution**: In paper trading, signals are executed against virtual portfolio

## Usage

### Starting Kafka Infrastructure

```bash
# Start Kafka cluster with topics
docker-compose up -d

# Verify topics are created
docker-compose logs kafka-init
```

### Running Trading Modes

```bash
# Kafka-based backtest mode
cargo run -- --strategy rsi --mode backtest

# Kafka-based paper trading
cargo run -- --strategy rsi --mode paper-trade-kafka

# Legacy backtest mode (original implementation)
cargo run -- --strategy rsi --mode backtest-legacy
```

### Custom Kafka Configuration

```bash
cargo run -- --strategy rsi --mode paper-trade-kafka \
  --kafka-brokers "localhost:9092" \
  --feature-topic "live-features" \
  --signal-topic "trading-signals" \
  --consumer-group "rsi-strategy"
```

## Testing

### Unit Tests
All modules include comprehensive unit tests for individual components.

### Integration Tests
Integration tests verify Kafka connectivity and end-to-end data flow:

```bash
# Start Kafka cluster first
docker-compose up -d

# Run integration tests (requires Kafka)
cargo test --test integration_tests -- --ignored
```

### Local Development Setup

1. **Start Kafka cluster**:
   ```bash
   docker-compose up -d
   ```

2. **Start feature generator**:
   ```bash
   docker-compose up feature-generator
   ```

3. **Access Kafka UI**:
   Open http://localhost:8080 to monitor topics and messages

4. **Run trading strategy**:
   ```bash
   cargo run -- --strategy rsi --mode paper-trade-kafka
   ```

## Docker Compose Services

- **zookeeper**: Kafka coordination service
- **kafka**: Message broker
- **schema-registry**: Schema management
- **kafka-ui**: Web interface for monitoring
- **kafka-init**: Topic initialization
- **feature-generator**: Mock market data generator

## Topics Created

- `features`: Market features (price, volume, indicators)
- `signals`: Trading signals from strategies
- `backtest-features`: Historical features for backtesting
- `live-features`: Real-time market features
- `paper-trade-signals`: Paper trading signals
- `portfolio-updates`: Portfolio state changes

## Configuration

### KafkaConfig
```rust
pub struct KafkaConfig {
    pub brokers: String,           // "localhost:9092"
    pub feature_topic: String,     // "features"
    pub signal_topic: String,      // "signals"
    pub consumer_group: String,    // "trading-strategy"
}
```

### Feature Format
```json
{
  "timestamp": "2025-01-31T12:00:00Z",
  "asset": "BTC",
  "feature_type": "price",
  "value": 50000.0,
  "metadata": {
    "source": "exchange_api",
    "confidence": "high"
  }
}
```

### Signal Format
```json
{
  "id": "uuid-v4",
  "timestamp": "2025-01-31T12:00:00Z",
  "asset": "BTC",
  "signal_type": "Buy",
  "strength": 0.8,
  "price": 50000.0,
  "quantity": 0.1,
  "strategy": "RSI Strategy",
  "metadata": {
    "mode": "paper_trade",
    "portfolio_value": "10500.0"
  }
}
```

## Performance Considerations

- **Consumer Groups**: Use different consumer groups for different strategy instances
- **Partitioning**: Features are partitioned by asset for parallel processing
- **Batching**: Signals can be batched for improved throughput
- **Timeouts**: Configurable timeouts for Kafka operations

## Error Handling

- **Connection Failures**: Automatic retry with exponential backoff
- **Deserialization Errors**: Logged and skipped, processing continues
- **Invalid Signals**: Validated before publishing
- **Resource Cleanup**: Proper cleanup on shutdown

## Monitoring

Use Kafka UI (http://localhost:8080) to monitor:
- Topic throughput and lag
- Consumer group status
- Message inspection
- Partition distribution

## Future Enhancements

1. **Schema Registry Integration**: Avro schemas for type safety
2. **Multi-Exchange Support**: Features from multiple data sources  
3. **Real-time Risk Management**: Risk signals published to dedicated topics
4. **Historical Data Replay**: Replay historical features for backtesting
5. **Performance Metrics**: Real-time strategy performance metrics
6. **Alert System**: Kafka-based alerting for significant events